# World-Model
This is a growing paper list of world model. Currently, I am **actively** updating it.

## 2023
Micheli, Alonso and Fran√ßois Fleuret, 2023. Transformers are Sample-Efficient World Models. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=vhFu1Acb0xb) | [pdf](https://openreview.net/pdf?id=vhFu1Acb0xb) ]

Hu et al., 2023. Planning Goals for Exploration. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=6qeBuZSo7Pr) | [pdf](https://openreview.net/pdf?id=6qeBuZSo7Pr) ]

Zhu, Li and Elhoseiny, 2023. Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=UYcIheNY9Pf) | [pdf](https://openreview.net/pdf?id=UYcIheNY9Pf) ]

Robine et al., 2023. Transformer-based World Models Are Happy With 100k Interactions. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=TdBaDGCpjly) | [pdf](https://openreview.net/pdf?id=TdBaDGCpjly) ]

Dorka, Welschehold and Burgard, 2023. Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=ZIkHSXzd9O7) | [pdf](https://openreview.net/pdf?id=ZIkHSXzd9O7) ]

Nakano, Suzuki and Matsuo, 2023. Interaction-Based Disentanglement of Entities for Object-Centric World Models. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=JQc2VowqCzz) | [pdf](https://openreview.net/pdf?id=JQc2VowqCzz) ]

## 2021
Friston wt al., 2021. World model learning and inference. Neural Networks. [ [www](https://psycnet.apa.org/record/2022-02182-049) | [pdf](https://web.archive.org/web/20211028143837id_/https://discovery.ucl.ac.uk/id/eprint/10137112/1/Friston_1-s2.0-S0893608021003610-main.pdf)]

Zhang, Yang and Stadie, 2021. World Model as a Graph: Learning Latent Landmarks for Planning. In International Conference on Machine Learning. [ [www](https://proceedings.mlr.press/v139/zhang21x.html) | [pdf](http://proceedings.mlr.press/v139/zhang21x/zhang21x.pdf) ]

Ball et al., 2021. Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v139/ball21a.html) | [pdf](http://proceedings.mlr.press/v139/ball21a/ball21a.pdf) ]

## 2020
Kim et al., 2020. Active World Model Learning with Progress Curiosity. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v119/kim20e.html) | [pdf](http://proceedings.mlr.press/v119/kim20e/kim20e.pdf) ]

Sekar et al., 2020. Planning to Explore via Self-Supervised World Models. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v119/sekar20a.html) | [pdf](http://proceedings.mlr.press/v119/sekar20a/sekar20a.pdf) ]

Lin et al., 2020. Improving Generative Imagination in Object-Centric World Models. In International Conference on Machine Learning. [ [www](https://proceedings.mlr.press/v119/lin20f.html) | [pdf](http://proceedings.mlr.press/v119/lin20f/lin20f.pdf)]

## 2018
Ha and Schmidhuber, 2018. Recurrent World Models Facilitate Policy Evolution. In Neural Information Processing Systems. [ [www](https://proceedings.neurips.cc/paper/2018/hash/2de5d16682c3c35007e4e92982f1a2ba-Abstract.html) | [pdf](https://proceedings.neurips.cc/paper/2018/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf) ]
