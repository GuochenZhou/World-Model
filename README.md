# World-Model
This is a growing paper list of world model. Currently, I am **actively** updating it.

## 2023
Micheli, Alonso and Fran√ßois Fleuret, 2023. Transformers are Sample-Efficient World Models. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=vhFu1Acb0xb) | [pdf](https://openreview.net/pdf?id=vhFu1Acb0xb) ]

Hu et al., 2023. Planning Goals for Exploration. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=6qeBuZSo7Pr) | [pdf](https://openreview.net/pdf?id=6qeBuZSo7Pr) ]

Zhu, Li and Elhoseiny, 2023. Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=UYcIheNY9Pf) | [pdf](https://openreview.net/pdf?id=UYcIheNY9Pf) ]

Robine et al., 2023. Transformer-based World Models Are Happy With 100k Interactions. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=TdBaDGCpjly) | [pdf](https://openreview.net/pdf?id=TdBaDGCpjly) ]

Dorka, Welschehold and Burgard, 2023. Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=ZIkHSXzd9O7) | [pdf](https://openreview.net/pdf?id=ZIkHSXzd9O7) ]

Nakano, Suzuki and Matsuo, 2023. Interaction-Based Disentanglement of Entities for Object-Centric World Models. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=JQc2VowqCzz) | [pdf](https://openreview.net/pdf?id=JQc2VowqCzz) ]

## 2022
Matsuo et al., 2022. Deep learning, reinforcement learning, and world models. Neural Networks. [ [www](https://www.sciencedirect.com/science/article/pii/S0893608022001150) | [pdf](https://pdf.sciencedirectassets.com/271125/1-s2.0-S0893608022X00063/1-s2.0-S0893608022001150/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEJD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCICrLKPmGgsitGiTAGuZthrpAmymIu73AK%2BJhniCsZdweAiAwiWbbnosI6oAINSLLW9nJqWfdmJJcZSUoEKVDKqfcXiqzBQhZEAUaDDA1OTAwMzU0Njg2NSIM7AoxxPicRBaHjkHNKpAFcDbJ1tXIN7vk69eVp%2F44bpNgPF4PlsmfhXvxK0rnDGOQmUmjxRQTE96boQSRc7E2tuUph48kRtPIRCKp88pEEYKyLxLrVLFbjh79cNJB%2BfKfHVUG6RGHttmvOu0sQXSwaGiBlMBxTRSVTZSlgo2aLBaaGLtS%2BpNWwwpmlxSuUjWALDRJcjr4LBd%2BOYZorbmlNMibDtnJYx0hHch3%2FezgRt5ozRU6gY2IkF1ZdrObb9l8WpTyjd9Xa0%2Fy6%2FLPaHvWim8k1YBOwq%2BTiMBY5MOGDC0uzw%2BvZRTpO2lGulHTg%2F5rqnUc9lfFyhnyzizdIoeeIQLWvdPUSM93yVuOlDd1ehoVbAzkEyTDKUZND%2FmJLV1DXBFL8rcq4gJU1HtDWdhkngb5py7X3%2Bdi8AgbZrpPHIujOBAaU8UgjpWTE3aXNWgc3ZMEr0XR76Kql36%2FWkffS0yTEEhklYSQrbuvZCNR9qL0DRCVgsr71pbV69jN%2FqtoszSfFUMW92omPc8glxVx6BZkBHbgTgvQ0VIsh0NyCjHHZ8qQ3nbxiPgt1Hx81GlkVqN3aSUFVaITiqGXuR03tgtTaQ7Og%2FicfDpgNh4Db0BwA7CcP%2F4Jawuf4JNre7T7B8%2FRwRMaWlDSXCvqndNQiovi8IwwYebKy6MGppMXwMKGBE3vtO3xOo6uL%2FWkVxCzvwnLNmC7122GSk6F5fu86wTWteWyym4fRWmtTtguo3dUmMQpBNyedYaBT4rqTh0JXnac6dhnKdGbiQMQHYb%2FelY88WyoPLt9doqnE14dyYTHzjgcWlJ9V1i%2BCDiOdsDvviVqybioLK4wDV9E6ADM%2FEkHJb1rRtefHiA8bLKgPk3fLJ63b6swd%2BcaAkS7fA4w74DboAY6sgGRoLuL%2BH41JGZqn5LSy%2FJkr2euOSCHvJ4kGdVOrogVPOG6%2FasifNcE6WD3rnXdtpgLNLQvel0fyOUIC6q7aYyMd0LzkgTmdOE1xvqvqjlkoJGeMPM6PgGGMsoxFXMV8M%2BnNjsuxti9Fni22aWMX4XwgOsycsyhaOvFirGswZxk%2BHwN5d6fbWBKyqejjN9YDgGLfYp3Wr3Tst6tCtQmQm9YnnbbAAY3o7Dy5n%2Bzwj5UZlTO&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230319T085243Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYSDGSGBVG%2F20230319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=916ae9f1e3197e5385f8f26a95c85dd20bd27e38e2f9c26d678fd1835186ecc5&hash=b9cd03b635e19d3782561c3a11f92d8f031590154a367238d9d2ff288cd23322&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0893608022001150&tid=spdf-bb7047c8-1a29-4e25-b068-37c157752bbe&sid=329db40428a0d5487a8bc2502e9954ff3f99gxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=190c5705045a53055204&rr=7aa47b1bd9fdaf37&cc=cn)]

Sancaktar, Blaes and Martius, 2022. Curious Exploration via Structured World Models Yields Zero-Shot Object Manipulation. In Neural Information Processing Systems. [ [www](https://openreview.net/forum?id=NnuYZ1el24C) | [pdf](https://openreview.net/pdf?id=NnuYZ1el24C) ]

## 2021
Friston wt al., 2021. World model learning and inference. Neural Networks. [ [www](https://psycnet.apa.org/record/2022-02182-049) | [pdf](https://web.archive.org/web/20211028143837id_/https://discovery.ucl.ac.uk/id/eprint/10137112/1/Friston_1-s2.0-S0893608021003610-main.pdf) ]

Zhang, Yang and Stadie, 2021. World Model as a Graph: Learning Latent Landmarks for Planning. In International Conference on Machine Learning. [ [www](https://proceedings.mlr.press/v139/zhang21x.html) | [pdf](http://proceedings.mlr.press/v139/zhang21x/zhang21x.pdf) ]

Ball et al., 2021. Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v139/ball21a.html) | [pdf](http://proceedings.mlr.press/v139/ball21a/ball21a.pdf) ]

Mendonca et al., 2021. Discovering and Achieving Goals via World Models. In Neural Information Processing Systems. [ [www](https://proceedings.neurips.cc/paper/2021/hash/cc4af25fa9d2d5c953496579b75f6f6c-Abstract.html) | [pdf](https://proceedings.neurips.cc/paper/2021/file/cc4af25fa9d2d5c953496579b75f6f6c-Paper.pdf) ]

Hafner et al., 2021. Mastering Atari with Discrete World Models. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=0oabwyZbOu) | [pdf](https://openreview.net/pdf?id=0oabwyZbOu) ]

## 2020
Kim et al., 2020. Active World Model Learning with Progress Curiosity. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v119/kim20e.html) | [pdf](http://proceedings.mlr.press/v119/kim20e/kim20e.pdf) ]

Sekar et al., 2020. Planning to Explore via Self-Supervised World Models. In International Conference on Machine Learning. [ [www](http://proceedings.mlr.press/v119/sekar20a.html) | [pdf](http://proceedings.mlr.press/v119/sekar20a/sekar20a.pdf) ]

Lin et al., 2020. Improving Generative Imagination in Object-Centric World Models. In International Conference on Machine Learning. [ [www](https://proceedings.mlr.press/v119/lin20f.html) | [pdf](http://proceedings.mlr.press/v119/lin20f/lin20f.pdf) ]

Jiang et al., 2020. Scalor: Generative world models with scalable object representations. In International Conference on Learning Representations. [ [www](https://openreview.net/forum?id=SJxrKgStDH) | [pdf](https://openreview.net/pdf?id=SJxrKgStDH) ]

## 2019
Freeman, Ha and Metz, 2019. Learning to Predict Without Looking Ahead: World Models Without Forward Prediction. In Neural Information Processing Systems. [ [www](https://proceedings.neurips.cc/paper/2019/hash/15cf76466b97264765356fcc56d801d1-Abstract.html) | [pdf](https://proceedings.neurips.cc/paper/2019/file/15cf76466b97264765356fcc56d801d1-Paper.pdf) ]

## 2018
Ha and Schmidhuber, 2018. Recurrent World Models Facilitate Policy Evolution. In Neural Information Processing Systems. [ [www](https://proceedings.neurips.cc/paper/2018/hash/2de5d16682c3c35007e4e92982f1a2ba-Abstract.html) | [pdf](https://proceedings.neurips.cc/paper/2018/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf) ]
